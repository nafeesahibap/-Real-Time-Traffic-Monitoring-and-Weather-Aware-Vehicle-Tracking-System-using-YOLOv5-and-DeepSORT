{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab5cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Clone YOLOv5 and install dependencies\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt\n",
    "!pip install deep_sort_realtime opencv-python-headless matplotlib\n",
    "\n",
    "# STEP 2: Upload 'input.mp4'\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload your 'input.mp4'\n",
    "\n",
    "# STEP 3: Imports\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from yolov5.models.common import DetectMultiBackend\n",
    "from yolov5.utils.general import non_max_suppression, scale_boxes\n",
    "from yolov5.utils.augmentations import letterbox\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# STEP 4: Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DetectMultiBackend('yolov5s.pt', device=device)\n",
    "model.eval()\n",
    "\n",
    "# Video setup\n",
    "video_path = 'input.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# DeepSORT & Tracking Variables\n",
    "deepsort = DeepSort()\n",
    "track_history = defaultdict(list)\n",
    "counted_ids_in = set()\n",
    "counted_ids_out = set()\n",
    "car_count_in = 0\n",
    "car_count_out = 0\n",
    "\n",
    "# Lines for counting\n",
    "entry_line_y = int(height * 0.4)\n",
    "exit_line_y = int(height * 0.6)\n",
    "\n",
    "# Classes to track (car=2, motorcycle=3, bus=5, truck=7)\n",
    "VEHICLE_CLASSES = [2, 3, 5, 7]\n",
    "\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    # Preprocess\n",
    "    img = letterbox(frame, new_shape=640)[0]\n",
    "    img = img[:, :, ::-1].transpose(2, 0, 1)\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img_tensor = torch.from_numpy(img).to(device).float() / 255.0\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        pred = model(img_tensor, augment=False)\n",
    "        pred = non_max_suppression(pred, conf_thres=0.3, iou_thres=0.4)[0]\n",
    "\n",
    "    detections = []\n",
    "    if pred is not None and len(pred):\n",
    "        pred[:, :4] = scale_boxes(img_tensor.shape[2:], pred[:, :4], frame.shape).round()\n",
    "        for *xyxy, conf, cls in pred:\n",
    "            if int(cls.item()) in VEHICLE_CLASSES:\n",
    "                x1, y1, x2, y2 = map(int, xyxy)\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "                if w > 0 and h > 0:  # Only valid boxes\n",
    "                    detections.append(([x1, y1, w, h], conf.item(), 'vehicle'))\n",
    "\n",
    "    # DeepSORT Tracking\n",
    "    tracks = deepsort.update_tracks(detections, frame=frame)\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        l, t, r, b = map(int, track.to_ltrb())\n",
    "        cx = int((l + r) / 2)\n",
    "        cy = int((t + b) / 2)\n",
    "\n",
    "        # History\n",
    "        track_history[track_id].append((cx, cy, frame_count))\n",
    "        if len(track_history[track_id]) > 2:\n",
    "            track_history[track_id].pop(0)\n",
    "\n",
    "        # Speed in mph\n",
    "        speed = 0\n",
    "        if len(track_history[track_id]) == 2:\n",
    "            (x1, y1, f1), (x2, y2, f2) = track_history[track_id]\n",
    "            dist_px = np.linalg.norm([x2 - x1, y2 - y1])\n",
    "            time_elapsed = (f2 - f1) / fps\n",
    "            if time_elapsed > 0:\n",
    "                speed = (dist_px / time_elapsed) * 0.0447  # px/frame to mph\n",
    "\n",
    "        # Count logic\n",
    "        if len(track_history[track_id]) == 2:\n",
    "            (, y_prev, _), (, y_curr, _) = track_history[track_id]\n",
    "            if y_prev < entry_line_y <= y_curr and track_id not in counted_ids_in:\n",
    "                car_count_in += 1\n",
    "                counted_ids_in.add(track_id)\n",
    "            elif y_prev > exit_line_y >= y_curr and track_id not in counted_ids_out:\n",
    "                car_count_out += 1\n",
    "                counted_ids_out.add(track_id)\n",
    "\n",
    "        # Draw vehicle box and speed\n",
    "        cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'ID:{track_id} {speed:.1f} mph', (l, t - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    # Draw lines\n",
    "    cv2.line(frame, (0, entry_line_y), (width, entry_line_y), (255, 0, 255), 2)\n",
    "    cv2.line(frame, (0, exit_line_y), (width, exit_line_y), (0, 255, 255), 2)\n",
    "\n",
    "    # Count display\n",
    "    cv2.putText(frame, f'Incoming: {car_count_in}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n",
    "    cv2.putText(frame, f'Outgoing: {car_count_out}', (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"âœ… Done! Download your 'output.mp4' from the sidebar.\")\n",
    "\n",
    "# Download output\n",
    "from google.colab import files\n",
    "files.download('output.mp4')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
